Although the Streaming Slot Filling task was introduced by TREC this year, another closely related task - Cumulative Citation Recommendation (CCR) has been ongoing for a couple of years on a subset of the same corpus. The CCR task deals with having to find relevant documents for a given set of entities, and hence is an important subset of our task as well. We went through the reports from previous submissions to get a sense of the tools and approaches most commonly used. 
\begin{enumerate}
\item A common thread across all teams was the use of a search engine to index documents and make querying faster. This led us to the open source search engine Indri from the Lemur Project, details of which are in the subsequent sections. http://www.lemurproject.org/indri/
\item In the current corpus, only 0.4\% of the documents that do not explicitly mention an entity are relevant. This means that we don’t have to worry about retrieving documents that contain an indirect reference to our entity of interest. On the other hand, out of documents that mention an entity, 23.8\% are garbage, 35.3\% are garbage or neutral, and the rest relevant~\cite{gebre}. This means  that our focus should be on aggressively pruning out documents.
\item The existence of training data for this task enabled teams to use supervised learning approaches (SVMs, Markov Random Fields)~\cite{dalton}~\cite{kjersten}. The SSF task does not have any training data and hence we have to depend on unsupervised approaches such as bootstrapping. 
\end{enumerate}

Bootstrapping as a technique for extracting relations from text has been around for some time. Some of the previous works use Freebase, a large semantic database of several thousand relations, to provide distant supervision. Mintz et. al(2009)~\cite{mintz} uses a classifier based approach to extract relations. For each pair of entities that appears in some Freebase relation, they find all sentences containing those entities in a large unlabeled corpus and extract textual features to train a relation classiﬁer. This method is advantageous because it automatically extracts relations which is line with what what we wanted to do. At the same time, some of the slot values were not entities (e.g. AwardWon, Contact\_Meet\_PlaceTime). Sergey Brin (1998)~\cite{brin} used a bootstrapping approach for extracting book-author pairs from web corpuses. But, his methods were based on co-occurrence of pattern words. Banko et. al. uses a classifier based approach to extract relations based on the words that appear in between. These methods wouldn’t scale for corpora of the size of the TREC KBA as classifiers had to be trained and features extracted for a several combinations of entity pairs. As a result, we use dependency parse of a sentence for relation extraction, which makes it easier to just look at the desired edges between patterns and extract the information we need. Another motivation to use the dependency parse was that the state of the art NLP parsers perform quite well and makes it easier to extract patterns in comparison to classifier based approaches.

